---
title: Analisis Prediktif Penyakit Jantung Menggunakan Algoritma Klasifikasi (Random
  Forest)
author: "Nama Anda"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
  html_document:
    toc: true
    toc_float: true
    theme: united
---

```{r setup, include=FALSE}
# Blok setup untuk konfigurasi global
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Muat library yang dibutuhkan
library(tidyverse)
library(caret)
library(randomForest)
```

## 1. Judul Proyek

Analisis Prediktif Penyakit Jantung Menggunakan Algoritma Klasifikasi (Random Forest) Berbasis Data Klinis.

## 2. Latar Belakang Masalah

Penyakit jantung adalah salah satu penyebab utama kematian secara global. Deteksi dini merupakan kunci untuk penanganan yang efektif dan peningkatan prognosis pasien. Data klinis pasien (seperti usia, tekanan darah, kolesterol, dan hasil EKG) menyimpan pola tersembunyi. Dengan menerapkan teknik data mining, kita dapat membangun model prediktif untuk mengidentifikasi individu yang berisiko tinggi terkena penyakit jantung, sehingga memungkinkan intervensi medis lebih awal.

## 3. Rumusan Masalah dan Tujuan Proyek

### Rumusan Masalah

1.  Bagaimana membangun model klasifikasi dengan akurasi tinggi untuk memprediksi apakah seorang pasien menderita penyakit jantung (`HeartDisease`) berdasarkan atribut klinis yang ada?
2.  Bagaimana menangani masalah kualitas data seperti nilai yang tidak logis (misalnya, Kolesterol '0') dalam dataset?
3.  Faktor klinis apa yang menjadi prediktor paling penting dalam menentukan risiko penyakit jantung?

### Tujuan Proyek

1.  Menerapkan metodologi CRISP-DM untuk memproses dan menganalisis dataset penyakit jantung.
2.  Membangun dan mengevaluasi model klasifikasi (fungsi mayor) menggunakan algoritma Random Forest.
3.  Menghasilkan model yang jujur dan robust dengan menerapkan teknik validasi silang (cross-validation) dan menghindari kebocoran data (*data leakage*).
4.  Mengidentifikasi variabel (fitur) yang paling berpengaruh terhadap prediksi penyakit jantung.

## 4. Sumber dan Karakteristik Data

* **Sumber Data:** Dataset publik "Heart Failure Prediction Dataset" yang diperoleh dari platform Kaggle.
* **Karakteristik Data:** Dataset awal terdiri dari 918 observasi (baris) dan 12 variabel (kolom).
* **Target Variabel:** `HeartDisease` (Biner: 1 = Sakit Jantung, 0 = Normal).
* **Variabel Prediktor:** Mencakup data demografis (`Age`, `Sex`), data klinis (`RestingBP`, `Cholesterol`), dan hasil tes (`MaxHR`, `RestingECG`, dll.).
* **Kualitas Data:** Terdapat potensi masalah kualitas data, seperti nilai '0' yang tidak logis pada kolom `Cholesterol` dan `RestingBP`, yang harus ditangani pada tahap *Data Preparation*.

## 5. Metodologi Data Mining (CRISP-DM)

Metodologi proyek mengikuti alur standar CRISP-DM.

### Tahap 1 & 2: Business & Data Understanding

Tahap ini mencakup pemahaman tujuan (telah dijelaskan di Latar Belakang) dan pemahaman data awal. Kita memuat data dan memeriksanya.

```{r data-understanding}
# Muat data
df <- read.csv("heart.csv")

# Tampilkan struktur data (mirip df.info())
glimpse(df)

# Tampilkan ringkasan statistik (mirip df.describe())
summary(df)
```

**Representasi (Temuan Awal):**
Dari `summary(df)`, kita melihat masalah kualitas data:
1.  `RestingBP` memiliki nilai minimum `0`.
2.  `Cholesterol` memiliki nilai minimum `0`.
Kedua nilai ini tidak mungkin secara biologis dan akan kita tangani sebagai data hilang.

### Tahap 3: Data Preparation

Ini adalah tahap kritis di mana kita membersihkan data, melakukan imputasi, dan membaginya.

```{r data-preparation-split}
# 1. Membersihkan 'RestingBP' (Drop baris karena jumlahnya sedikit)
df_clean <- df %>%
  filter(RestingBP > 0)
print(paste("Jumlah baris setelah membersihkan RestingBP:", nrow(df_clean)))

# 2. Split Data (WAJIB dilakukan SEBELUM imputasi untuk mencegah data leakage)
set.seed(26)
trainIndex <- createDataPartition(df_clean$HeartDisease, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_data <- df_clean[ trainIndex,]
test_data  <- df_clean[-trainIndex,]
```

```{r data-preparation-impute-factor}
# 3. Imputasi 'Cholesterol = 0'
# Hitung median HANYA dari data latih
valid_chol_median <- train_data %>%
  filter(Cholesterol > 0) %>%
  summarise(MedianChol = median(Cholesterol, na.rm = TRUE)) %>%
  pull(MedianChol)

print(paste("Median kolesterol (dari data latih):", valid_chol_median))

# Terapkan median ke data latih dan data uji
train_data <- train_data %>%
  mutate(Cholesterol = ifelse(Cholesterol == 0, valid_chol_median, Cholesterol))

test_data <- test_data %>%
  mutate(Cholesterol = ifelse(Cholesterol == 0, valid_chol_median, Cholesterol))

# 4. Konversi Variabel Kategorikal menjadi Factor
categorical_cols <- c('Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope', 'FastingBS', 'HeartDisease')

train_data <- train_data %>%
  mutate(across(all_of(categorical_cols), as.factor))

test_data <- test_data %>%
  mutate(across(all_of(categorical_cols), as.factor))

# Tampilkan struktur data latih setelah bersih
glimpse(train_data)
```

### Tahap 4: Modeling

Kita melatih model menggunakan data latih (`train_data`) dengan metode 10-Fold Cross-Validation (CV) untuk memastikan model stabil dan *robust*.

```{r modeling}
# Tentukan metode kontrol: 10-Fold CV
set.seed(18)
trControl <- trainControl(method = "cv",
                          number = 10) 

# Latih model Random Forest
# Kita juga menambahkan 'preProcess' untuk scaling (fungsi minor)
model_rf <- train(HeartDisease ~ ., 
                  data = train_data, 
                  method = "rf",
                  trControl = trControl,
                  preProcess = c("center", "scale")
                 )

# Representasi (Hasil Cross-Validation):
# Menampilkan akurasi rata-rata dari 10-fold CV
print(model_rf)
```

### Tahap 5: Evaluation

Model yang sudah dilatih (`model_rf`) kini dievaluasi kinerjanya menggunakan data uji (`test_data`) yang belum pernah dilihat sebelumnya.

```{r evaluation}
# Buat prediksi pada data uji
y_pred <- predict(model_rf, newdata = test_data)
y_test <- test_data$HeartDisease

# Representasi (Confusion Matrix dan Statistik Lengkap):
cm <- confusionMatrix(y_pred, y_test)
print(cm)
```

## 6. Teknik dan Algoritma yang Digunakan

* **Algoritma Utama:** **Random Forest**
* **Fungsi Mayor:** **Klasifikasi**. Tujuan model adalah mengklasifikasikan pasien ke dalam dua kelas: '0' (Sehat) atau '1' (Sakit Jantung).
* **Fungsi Minor:**
    * **Pembersihan Data:** Menghapus baris dengan `RestingBP = 0`.
    * **Imputasi:** Mengganti nilai `Cholesterol = 0` dengan **Median** dari data latih (bukan *mean*, untuk menghindari bias dari *outlier*).
    * **Transformasi Tipe Data:** Mengubah variabel objek (char) menjadi *factor* agar dapat diproses oleh R.
    * **Normalisasi (Scaling):** Menggunakan `center` dan `scale` (standarisasi Z-score) pada fitur numerik selama proses *training* untuk membantu beberapa algoritma (meskipun dampaknya minimal pada Random Forest, ini adalah *best practice*).

## 7. Rencana Implementasi dan Alat yang Digunakan

* **Alat Utama:** RStudio
* **Bahasa:** R
* **Paket (Library) Kunci:**
    * `tidyverse` (untuk manipulasi data/Data Preparation).
    * `caret` (untuk proses *split data*, *modeling*, *preprocessing*, dan *evaluation*).
    * `randomForest` (sebagai *engine* algoritma utama).
    * `ggplot2` (untuk visualisasi).

## 8. Hasil yang Diharapkan dan Dampak

### Hasil Proyek (Representasi Output)

1.  **Model Prediktif:** Sebuah model R (`model_rf`) yang siap digunakan, yang terbukti memiliki akurasi **`r round(cm$overall['Accuracy'], 3)`** dan Kappa **`r round(cm$overall['Kappa'], 3)`** pada data uji.
2.  **Visualisasi Hasil (Confusion Matrix):**

    ```{r plot-cm}
    # Plot heatmap confusion matrix
    cm_table <- as.data.frame(cm$table)
    ggplot(cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
      geom_tile(color = "white") +
      geom_text(aes(label = Freq), vjust = 1) +
      scale_fill_gradient(low = "white", high = "blue") +
      labs(title = "Confusion Matrix (Test Data)") +
      theme_minimal()
    ```

3.  **Insight Kunci (Variable Importance):** Kita dapat mengekstrak fitur apa yang dianggap paling penting oleh model.

    ```{r plot-importance}
    # Plot variable importance
    var_imp <- varImp(model_rf)
    plot(var_imp, main = "Variable Importance (Faktor Paling Berpengaruh)")
    ```

### Dampak dan Potensi Penerapan

Berdasarkan hasil di atas (terutama *Variable Importance*), kita dapat memberikan *insight* bagi praktisi medis. Model ini dapat digunakan sebagai **Sistem Pendukung Keputusan (Decision Support System)** untuk *screening* awal pasien. Pasien yang diprediksi memiliki risiko tinggi dapat segera dirujuk untuk pemeriksaan lebih lanjut, sehingga mempercepat proses diagnosis dan penanganan.